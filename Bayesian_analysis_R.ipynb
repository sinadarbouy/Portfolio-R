{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian analysis in R\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the data\n",
    "The data [Empirical-Software-Engineering](W. Afzal, A. N. Ghazi, J. Itkonen,\n",
    "R. Torkar, A. Andrews, and K. Bhatti.\n",
    "An experiment on the effectiveness\n",
    "and efficiency of exploratory testing.\n",
    "Empirical Software Engineering, 20(3):\n",
    "844–878, 2015. ISSN 1573-7616. doi:\n",
    "10.1007/s10664-014-9301-4 \"Empirical Software Engineering\") is from an experiment where 70 subjects participated. Of the 70, 46 subjects were categorized as less experienced (LE) and 24 were categorized as more experienced (ME). The experiment evaluated two software testing techniques, i.e., a new technique (NT) and an old technique (OT), used a small, noncritical system as the software under test, and had a 2 × 2 design to avoid learning bias. The effectiveness of each technique was measured through true positives (tp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: rstan\n",
      "\n",
      "Loading required package: StanHeaders\n",
      "\n",
      "Loading required package: ggplot2\n",
      "\n",
      "rstan (Version 2.21.2, GitRev: 2e1f913d3ca3)\n",
      "\n",
      "For execution on a local, multicore CPU with excess RAM we recommend calling\n",
      "options(mc.cores = parallel::detectCores()).\n",
      "To avoid recompilation of unchanged Stan programs, we recommend calling\n",
      "rstan_options(auto_write = TRUE)\n",
      "\n",
      "Do not specify '-march=native' in 'LOCAL_CPPFLAGS' or a Makevars file\n",
      "\n",
      "Loading required package: parallel\n",
      "\n",
      "rethinking (Version 2.13)\n",
      "\n",
      "\n",
      "Attaching package: 'rethinking'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:stats':\n",
      "\n",
      "    rstudent\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>subject</th><th scope=col>category</th><th scope=col>technique</th><th scope=col>tp</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1</td><td>LE</td><td>NT</td><td>5</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>1</td><td>LE</td><td>OT</td><td>6</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>2</td><td>LE</td><td>NT</td><td>3</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>2</td><td>LE</td><td>OT</td><td>3</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>3</td><td>LE</td><td>NT</td><td>7</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>3</td><td>LE</td><td>OT</td><td>3</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 4\n",
       "\\begin{tabular}{r|llll}\n",
       "  & subject & category & technique & tp\\\\\n",
       "  & <int> & <chr> & <chr> & <int>\\\\\n",
       "\\hline\n",
       "\t1 & 1 & LE & NT & 5\\\\\n",
       "\t2 & 1 & LE & OT & 6\\\\\n",
       "\t3 & 2 & LE & NT & 3\\\\\n",
       "\t4 & 2 & LE & OT & 3\\\\\n",
       "\t5 & 3 & LE & NT & 7\\\\\n",
       "\t6 & 3 & LE & OT & 3\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 4\n",
       "\n",
       "| <!--/--> | subject &lt;int&gt; | category &lt;chr&gt; | technique &lt;chr&gt; | tp &lt;int&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 1 | 1 | LE | NT | 5 |\n",
       "| 2 | 1 | LE | OT | 6 |\n",
       "| 3 | 2 | LE | NT | 3 |\n",
       "| 4 | 2 | LE | OT | 3 |\n",
       "| 5 | 3 | LE | NT | 7 |\n",
       "| 6 | 3 | LE | OT | 3 |\n",
       "\n"
      ],
      "text/plain": [
       "  subject category technique tp\n",
       "1 1       LE       NT        5 \n",
       "2 1       LE       OT        6 \n",
       "3 2       LE       NT        3 \n",
       "4 2       LE       OT        3 \n",
       "5 3       LE       NT        7 \n",
       "6 3       LE       OT        3 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(rethinking)\n",
    "d <- read.csv(\"https://raw.githubusercontent.com/torkar/dat321/master/data_autumn2020.csv\", sep=\";\") # nolint\n",
    "head(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive statistics\n",
    "First, I check the tp column I checked min, max, plot, density I saw\n",
    "that everything was normal then I checked the category, I checked 2 Descriptive statistics\n",
    "freq with library \"summarytools\" and I saw that everything fine then\n",
    "I checked the last column and I saw weird things \"0T\" so that is an\n",
    "error and I replace the \"0T\" to \"OT\".then I checked that every subject\n",
    "has two rows in our data with \"count\" Function. the variables we’ll\n",
    "need: in this assignment, I check Three likelihood one of them count\n",
    "base and the others real number base, so I have two data lists that\n",
    "one of I’ve standardized the outcome and in both data lists, tech\n",
    "is 1 for new technique and 2 for old technique and cat is 1 for less\n",
    "experience and 2 for more experience. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>subject</th><th scope=col>category</th><th scope=col>technique</th><th scope=col>tp</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1</td><td>LE</td><td>NT</td><td>5</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>1</td><td>LE</td><td>OT</td><td>6</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>2</td><td>LE</td><td>NT</td><td>3</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>2</td><td>LE</td><td>OT</td><td>3</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>3</td><td>LE</td><td>NT</td><td>7</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>3</td><td>LE</td><td>OT</td><td>3</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 4\n",
       "\\begin{tabular}{r|llll}\n",
       "  & subject & category & technique & tp\\\\\n",
       "  & <int> & <chr> & <chr> & <int>\\\\\n",
       "\\hline\n",
       "\t1 & 1 & LE & NT & 5\\\\\n",
       "\t2 & 1 & LE & OT & 6\\\\\n",
       "\t3 & 2 & LE & NT & 3\\\\\n",
       "\t4 & 2 & LE & OT & 3\\\\\n",
       "\t5 & 3 & LE & NT & 7\\\\\n",
       "\t6 & 3 & LE & OT & 3\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 4\n",
       "\n",
       "| <!--/--> | subject &lt;int&gt; | category &lt;chr&gt; | technique &lt;chr&gt; | tp &lt;int&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 1 | 1 | LE | NT | 5 |\n",
       "| 2 | 1 | LE | OT | 6 |\n",
       "| 3 | 2 | LE | NT | 3 |\n",
       "| 4 | 2 | LE | OT | 3 |\n",
       "| 5 | 3 | LE | NT | 7 |\n",
       "| 6 | 3 | LE | OT | 3 |\n",
       "\n"
      ],
      "text/plain": [
       "  subject category technique tp\n",
       "1 1       LE       NT        5 \n",
       "2 1       LE       OT        6 \n",
       "3 2       LE       NT        3 \n",
       "4 2       LE       OT        3 \n",
       "5 3       LE       NT        7 \n",
       "6 3       LE       OT        3 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t140 obs. of  4 variables:\n",
      " $ subject  : int  1 1 2 2 3 3 4 4 5 5 ...\n",
      " $ category : chr  \"LE\" \"LE\" \"LE\" \"LE\" ...\n",
      " $ technique: chr  \"NT\" \"OT\" \"NT\" \"OT\" ...\n",
      " $ tp       : int  5 6 3 3 7 3 6 4 11 5 ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "1"
      ],
      "text/latex": [
       "1"
      ],
      "text/markdown": [
       "1"
      ],
      "text/plain": [
       "[1] 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "11"
      ],
      "text/latex": [
       "11"
      ],
      "text/markdown": [
       "11"
      ],
      "text/plain": [
       "[1] 11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A summarytools: 4 × 5 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Freq</th><th scope=col>% Valid</th><th scope=col>% Valid Cum.</th><th scope=col>% Total</th><th scope=col>% Total Cum.</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>LE</th><td> 92</td><td> 65.71429</td><td> 65.71429</td><td> 65.71429</td><td> 65.71429</td></tr>\n",
       "\t<tr><th scope=row>ME</th><td> 48</td><td> 34.28571</td><td>100.00000</td><td> 34.28571</td><td>100.00000</td></tr>\n",
       "\t<tr><th scope=row>&lt;NA&gt;</th><td>  0</td><td>       NA</td><td>       NA</td><td>  0.00000</td><td>100.00000</td></tr>\n",
       "\t<tr><th scope=row>Total</th><td>140</td><td>100.00000</td><td>100.00000</td><td>100.00000</td><td>100.00000</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A summarytools: 4 × 5 of type dbl\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & Freq & \\% Valid & \\% Valid Cum. & \\% Total & \\% Total Cum.\\\\\n",
       "\\hline\n",
       "\tLE &  92 &  65.71429 &  65.71429 &  65.71429 &  65.71429\\\\\n",
       "\tME &  48 &  34.28571 & 100.00000 &  34.28571 & 100.00000\\\\\n",
       "\t<NA> &   0 &        NA &        NA &   0.00000 & 100.00000\\\\\n",
       "\tTotal & 140 & 100.00000 & 100.00000 & 100.00000 & 100.00000\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A summarytools: 4 × 5 of type dbl\n",
       "\n",
       "| <!--/--> | Freq | % Valid | % Valid Cum. | % Total | % Total Cum. |\n",
       "|---|---|---|---|---|---|\n",
       "| LE |  92 |  65.71429 |  65.71429 |  65.71429 |  65.71429 |\n",
       "| ME |  48 |  34.28571 | 100.00000 |  34.28571 | 100.00000 |\n",
       "| &lt;NA&gt; |   0 |        NA |        NA |   0.00000 | 100.00000 |\n",
       "| Total | 140 | 100.00000 | 100.00000 | 100.00000 | 100.00000 |\n",
       "\n"
      ],
      "text/plain": [
       "      Freq % Valid   % Valid Cum. % Total   % Total Cum.\n",
       "LE     92   65.71429  65.71429     65.71429  65.71429   \n",
       "ME     48   34.28571 100.00000     34.28571 100.00000   \n",
       "<NA>    0         NA        NA      0.00000 100.00000   \n",
       "Total 140  100.00000 100.00000    100.00000 100.00000   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'0T'"
      ],
      "text/latex": [
       "'0T'"
      ],
      "text/markdown": [
       "'0T'"
      ],
      "text/plain": [
       "[1] \"0T\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A summarytools: 5 × 5 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Freq</th><th scope=col>% Valid</th><th scope=col>% Valid Cum.</th><th scope=col>% Total</th><th scope=col>% Total Cum.</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>0T</th><td>  1</td><td>  0.7142857</td><td>  0.7142857</td><td>  0.7142857</td><td>  0.7142857</td></tr>\n",
       "\t<tr><th scope=row>NT</th><td> 70</td><td> 50.0000000</td><td> 50.7142857</td><td> 50.0000000</td><td> 50.7142857</td></tr>\n",
       "\t<tr><th scope=row>OT</th><td> 69</td><td> 49.2857143</td><td>100.0000000</td><td> 49.2857143</td><td>100.0000000</td></tr>\n",
       "\t<tr><th scope=row>&lt;NA&gt;</th><td>  0</td><td>         NA</td><td>         NA</td><td>  0.0000000</td><td>100.0000000</td></tr>\n",
       "\t<tr><th scope=row>Total</th><td>140</td><td>100.0000000</td><td>100.0000000</td><td>100.0000000</td><td>100.0000000</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A summarytools: 5 × 5 of type dbl\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & Freq & \\% Valid & \\% Valid Cum. & \\% Total & \\% Total Cum.\\\\\n",
       "\\hline\n",
       "\t0T &   1 &   0.7142857 &   0.7142857 &   0.7142857 &   0.7142857\\\\\n",
       "\tNT &  70 &  50.0000000 &  50.7142857 &  50.0000000 &  50.7142857\\\\\n",
       "\tOT &  69 &  49.2857143 & 100.0000000 &  49.2857143 & 100.0000000\\\\\n",
       "\t<NA> &   0 &          NA &          NA &   0.0000000 & 100.0000000\\\\\n",
       "\tTotal & 140 & 100.0000000 & 100.0000000 & 100.0000000 & 100.0000000\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A summarytools: 5 × 5 of type dbl\n",
       "\n",
       "| <!--/--> | Freq | % Valid | % Valid Cum. | % Total | % Total Cum. |\n",
       "|---|---|---|---|---|---|\n",
       "| 0T |   1 |   0.7142857 |   0.7142857 |   0.7142857 |   0.7142857 |\n",
       "| NT |  70 |  50.0000000 |  50.7142857 |  50.0000000 |  50.7142857 |\n",
       "| OT |  69 |  49.2857143 | 100.0000000 |  49.2857143 | 100.0000000 |\n",
       "| &lt;NA&gt; |   0 |          NA |          NA |   0.0000000 | 100.0000000 |\n",
       "| Total | 140 | 100.0000000 | 100.0000000 | 100.0000000 | 100.0000000 |\n",
       "\n"
      ],
      "text/plain": [
       "      Freq % Valid     % Valid Cum. % Total     % Total Cum.\n",
       "0T      1    0.7142857   0.7142857    0.7142857   0.7142857 \n",
       "NT     70   50.0000000  50.7142857   50.0000000  50.7142857 \n",
       "OT     69   49.2857143 100.0000000   49.2857143 100.0000000 \n",
       "<NA>    0           NA          NA    0.0000000 100.0000000 \n",
       "Total 140  100.0000000 100.0000000  100.0000000 100.0000000 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 70 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>subject</th><th scope=col>freq</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td> 1</td><td>2</td></tr>\n",
       "\t<tr><td> 2</td><td>2</td></tr>\n",
       "\t<tr><td> 3</td><td>2</td></tr>\n",
       "\t<tr><td> 4</td><td>2</td></tr>\n",
       "\t<tr><td> 5</td><td>2</td></tr>\n",
       "\t<tr><td> 6</td><td>2</td></tr>\n",
       "\t<tr><td> 7</td><td>2</td></tr>\n",
       "\t<tr><td> 8</td><td>2</td></tr>\n",
       "\t<tr><td> 9</td><td>2</td></tr>\n",
       "\t<tr><td>10</td><td>2</td></tr>\n",
       "\t<tr><td>11</td><td>2</td></tr>\n",
       "\t<tr><td>12</td><td>2</td></tr>\n",
       "\t<tr><td>13</td><td>2</td></tr>\n",
       "\t<tr><td>14</td><td>2</td></tr>\n",
       "\t<tr><td>15</td><td>2</td></tr>\n",
       "\t<tr><td>16</td><td>2</td></tr>\n",
       "\t<tr><td>17</td><td>2</td></tr>\n",
       "\t<tr><td>18</td><td>2</td></tr>\n",
       "\t<tr><td>19</td><td>2</td></tr>\n",
       "\t<tr><td>20</td><td>2</td></tr>\n",
       "\t<tr><td>21</td><td>2</td></tr>\n",
       "\t<tr><td>22</td><td>2</td></tr>\n",
       "\t<tr><td>23</td><td>2</td></tr>\n",
       "\t<tr><td>24</td><td>2</td></tr>\n",
       "\t<tr><td>25</td><td>2</td></tr>\n",
       "\t<tr><td>26</td><td>2</td></tr>\n",
       "\t<tr><td>27</td><td>2</td></tr>\n",
       "\t<tr><td>28</td><td>2</td></tr>\n",
       "\t<tr><td>29</td><td>2</td></tr>\n",
       "\t<tr><td>30</td><td>2</td></tr>\n",
       "\t<tr><td>...</td><td>...</td></tr>\n",
       "\t<tr><td>41</td><td>2</td></tr>\n",
       "\t<tr><td>42</td><td>2</td></tr>\n",
       "\t<tr><td>43</td><td>2</td></tr>\n",
       "\t<tr><td>44</td><td>2</td></tr>\n",
       "\t<tr><td>45</td><td>2</td></tr>\n",
       "\t<tr><td>46</td><td>2</td></tr>\n",
       "\t<tr><td>47</td><td>2</td></tr>\n",
       "\t<tr><td>48</td><td>2</td></tr>\n",
       "\t<tr><td>49</td><td>2</td></tr>\n",
       "\t<tr><td>50</td><td>2</td></tr>\n",
       "\t<tr><td>51</td><td>2</td></tr>\n",
       "\t<tr><td>52</td><td>2</td></tr>\n",
       "\t<tr><td>53</td><td>2</td></tr>\n",
       "\t<tr><td>54</td><td>2</td></tr>\n",
       "\t<tr><td>55</td><td>2</td></tr>\n",
       "\t<tr><td>56</td><td>2</td></tr>\n",
       "\t<tr><td>57</td><td>2</td></tr>\n",
       "\t<tr><td>58</td><td>2</td></tr>\n",
       "\t<tr><td>59</td><td>2</td></tr>\n",
       "\t<tr><td>60</td><td>2</td></tr>\n",
       "\t<tr><td>61</td><td>2</td></tr>\n",
       "\t<tr><td>62</td><td>2</td></tr>\n",
       "\t<tr><td>63</td><td>2</td></tr>\n",
       "\t<tr><td>64</td><td>2</td></tr>\n",
       "\t<tr><td>65</td><td>2</td></tr>\n",
       "\t<tr><td>66</td><td>2</td></tr>\n",
       "\t<tr><td>67</td><td>2</td></tr>\n",
       "\t<tr><td>68</td><td>2</td></tr>\n",
       "\t<tr><td>69</td><td>2</td></tr>\n",
       "\t<tr><td>70</td><td>2</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 70 × 2\n",
       "\\begin{tabular}{ll}\n",
       " subject & freq\\\\\n",
       " <int> & <int>\\\\\n",
       "\\hline\n",
       "\t  1 & 2\\\\\n",
       "\t  2 & 2\\\\\n",
       "\t  3 & 2\\\\\n",
       "\t  4 & 2\\\\\n",
       "\t  5 & 2\\\\\n",
       "\t  6 & 2\\\\\n",
       "\t  7 & 2\\\\\n",
       "\t  8 & 2\\\\\n",
       "\t  9 & 2\\\\\n",
       "\t 10 & 2\\\\\n",
       "\t 11 & 2\\\\\n",
       "\t 12 & 2\\\\\n",
       "\t 13 & 2\\\\\n",
       "\t 14 & 2\\\\\n",
       "\t 15 & 2\\\\\n",
       "\t 16 & 2\\\\\n",
       "\t 17 & 2\\\\\n",
       "\t 18 & 2\\\\\n",
       "\t 19 & 2\\\\\n",
       "\t 20 & 2\\\\\n",
       "\t 21 & 2\\\\\n",
       "\t 22 & 2\\\\\n",
       "\t 23 & 2\\\\\n",
       "\t 24 & 2\\\\\n",
       "\t 25 & 2\\\\\n",
       "\t 26 & 2\\\\\n",
       "\t 27 & 2\\\\\n",
       "\t 28 & 2\\\\\n",
       "\t 29 & 2\\\\\n",
       "\t 30 & 2\\\\\n",
       "\t ... & ...\\\\\n",
       "\t 41 & 2\\\\\n",
       "\t 42 & 2\\\\\n",
       "\t 43 & 2\\\\\n",
       "\t 44 & 2\\\\\n",
       "\t 45 & 2\\\\\n",
       "\t 46 & 2\\\\\n",
       "\t 47 & 2\\\\\n",
       "\t 48 & 2\\\\\n",
       "\t 49 & 2\\\\\n",
       "\t 50 & 2\\\\\n",
       "\t 51 & 2\\\\\n",
       "\t 52 & 2\\\\\n",
       "\t 53 & 2\\\\\n",
       "\t 54 & 2\\\\\n",
       "\t 55 & 2\\\\\n",
       "\t 56 & 2\\\\\n",
       "\t 57 & 2\\\\\n",
       "\t 58 & 2\\\\\n",
       "\t 59 & 2\\\\\n",
       "\t 60 & 2\\\\\n",
       "\t 61 & 2\\\\\n",
       "\t 62 & 2\\\\\n",
       "\t 63 & 2\\\\\n",
       "\t 64 & 2\\\\\n",
       "\t 65 & 2\\\\\n",
       "\t 66 & 2\\\\\n",
       "\t 67 & 2\\\\\n",
       "\t 68 & 2\\\\\n",
       "\t 69 & 2\\\\\n",
       "\t 70 & 2\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 70 × 2\n",
       "\n",
       "| subject &lt;int&gt; | freq &lt;int&gt; |\n",
       "|---|---|\n",
       "|  1 | 2 |\n",
       "|  2 | 2 |\n",
       "|  3 | 2 |\n",
       "|  4 | 2 |\n",
       "|  5 | 2 |\n",
       "|  6 | 2 |\n",
       "|  7 | 2 |\n",
       "|  8 | 2 |\n",
       "|  9 | 2 |\n",
       "| 10 | 2 |\n",
       "| 11 | 2 |\n",
       "| 12 | 2 |\n",
       "| 13 | 2 |\n",
       "| 14 | 2 |\n",
       "| 15 | 2 |\n",
       "| 16 | 2 |\n",
       "| 17 | 2 |\n",
       "| 18 | 2 |\n",
       "| 19 | 2 |\n",
       "| 20 | 2 |\n",
       "| 21 | 2 |\n",
       "| 22 | 2 |\n",
       "| 23 | 2 |\n",
       "| 24 | 2 |\n",
       "| 25 | 2 |\n",
       "| 26 | 2 |\n",
       "| 27 | 2 |\n",
       "| 28 | 2 |\n",
       "| 29 | 2 |\n",
       "| 30 | 2 |\n",
       "| ... | ... |\n",
       "| 41 | 2 |\n",
       "| 42 | 2 |\n",
       "| 43 | 2 |\n",
       "| 44 | 2 |\n",
       "| 45 | 2 |\n",
       "| 46 | 2 |\n",
       "| 47 | 2 |\n",
       "| 48 | 2 |\n",
       "| 49 | 2 |\n",
       "| 50 | 2 |\n",
       "| 51 | 2 |\n",
       "| 52 | 2 |\n",
       "| 53 | 2 |\n",
       "| 54 | 2 |\n",
       "| 55 | 2 |\n",
       "| 56 | 2 |\n",
       "| 57 | 2 |\n",
       "| 58 | 2 |\n",
       "| 59 | 2 |\n",
       "| 60 | 2 |\n",
       "| 61 | 2 |\n",
       "| 62 | 2 |\n",
       "| 63 | 2 |\n",
       "| 64 | 2 |\n",
       "| 65 | 2 |\n",
       "| 66 | 2 |\n",
       "| 67 | 2 |\n",
       "| 68 | 2 |\n",
       "| 69 | 2 |\n",
       "| 70 | 2 |\n",
       "\n"
      ],
      "text/plain": [
       "    subject freq\n",
       "1    1      2   \n",
       "2    2      2   \n",
       "3    3      2   \n",
       "4    4      2   \n",
       "5    5      2   \n",
       "6    6      2   \n",
       "7    7      2   \n",
       "8    8      2   \n",
       "9    9      2   \n",
       "10  10      2   \n",
       "11  11      2   \n",
       "12  12      2   \n",
       "13  13      2   \n",
       "14  14      2   \n",
       "15  15      2   \n",
       "16  16      2   \n",
       "17  17      2   \n",
       "18  18      2   \n",
       "19  19      2   \n",
       "20  20      2   \n",
       "21  21      2   \n",
       "22  22      2   \n",
       "23  23      2   \n",
       "24  24      2   \n",
       "25  25      2   \n",
       "26  26      2   \n",
       "27  27      2   \n",
       "28  28      2   \n",
       "29  29      2   \n",
       "30  30      2   \n",
       "... ...     ... \n",
       "41  41      2   \n",
       "42  42      2   \n",
       "43  43      2   \n",
       "44  44      2   \n",
       "45  45      2   \n",
       "46  46      2   \n",
       "47  47      2   \n",
       "48  48      2   \n",
       "49  49      2   \n",
       "50  50      2   \n",
       "51  51      2   \n",
       "52  52      2   \n",
       "53  53      2   \n",
       "54  54      2   \n",
       "55  55      2   \n",
       "56  56      2   \n",
       "57  57      2   \n",
       "58  58      2   \n",
       "59  59      2   \n",
       "60  60      2   \n",
       "61  61      2   \n",
       "62  62      2   \n",
       "63  63      2   \n",
       "64  64      2   \n",
       "65  65      2   \n",
       "66  66      2   \n",
       "67  67      2   \n",
       "68  68      2   \n",
       "69  69      2   \n",
       "70  70      2   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Plot with title \"density.default(x = d$tp)\""
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#_____________Descriptive statistics_________\n",
    "head(d)\n",
    "str(d)\n",
    "\n",
    "#First check tp\n",
    "min(d$tp)\n",
    "max(d$tp)\n",
    "plot(d$tp)\n",
    "plot(density(d$tp))\n",
    "\n",
    "#Second Check category\n",
    "library(summarytools)\n",
    "freq(d$category)\n",
    "\n",
    "#third check technique\n",
    "#______________Find Something________________\n",
    "min(d$technique) #  \"0T\" !!\n",
    "library(summarytools)\n",
    "freq(d$technique) #find three categury !!\n",
    "\n",
    "library(plyr)\n",
    "count(d, \"subject\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d$technique[d$technique == \"0T\"] <- \"OT\" #Fix the error\n",
    "\n",
    "dat_list <- list(\n",
    "    tp = standardize(d$tp),\n",
    "    T = ifelse(d$technique == \"NT\", 1L, 2L),\n",
    "    C = ifelse(d$category == \"LE\", 1L, 2L)\n",
    ")\n",
    "\n",
    "dat_list2 <- list(\n",
    "    tp = d$tp,\n",
    "    T = ifelse(d$technique == \"NT\", 1L, 2L),\n",
    "    C = ifelse(d$category == \"LE\", 1L, 2L)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "### likelihood(s)\n",
    "I have two options for choosing likelihood one of them going base real number the other one going base count number and I want to compare these two models and show that \"Is it good to standardize and convert discrete numbers to  Real numbers or not?\" so for count base number I have Two options one of them is binomial and the other one is Poisson and because we have a low rate for Score so I choose Poisson and in Poisson I have two other options one of them Standard Poisson and the other one Gama Poisson at first I check mean and variance of tp 4 and I saw that there is a little difference so There should not be much difference between the two likelihoods So I choose Poisson for Three reasons:\n",
    "1. Count Events With Low rate \n",
    "2. Mean and Variance are almost equal \n",
    "3. we don’t have many trials so adding parameters Probably not a good idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventually, I became curious to check Gama-Poisson too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Priors\n",
    "To define prior I need to find mean, min, max of data for both desecrate number data and real number data so at first, I calculate them. I have 6 models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "6.14138576303182e-17"
      ],
      "text/latex": [
       "6.14138576303182e-17"
      ],
      "text/markdown": [
       "6.14138576303182e-17"
      ],
      "text/plain": [
       "[1] 6.141386e-17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "-1.86899866450574"
      ],
      "text/latex": [
       "-1.86899866450574"
      ],
      "text/markdown": [
       "-1.86899866450574"
      ],
      "text/plain": [
       "[1] -1.868999"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "3.07731160072684"
      ],
      "text/latex": [
       "3.07731160072684"
      ],
      "text/markdown": [
       "3.07731160072684"
      ],
      "text/plain": [
       "[1] 3.077312"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "4.77857142857143"
      ],
      "text/latex": [
       "4.77857142857143"
      ],
      "text/markdown": [
       "4.77857142857143"
      ],
      "text/plain": [
       "[1] 4.778571"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "1"
      ],
      "text/latex": [
       "1"
      ],
      "text/markdown": [
       "1"
      ],
      "text/plain": [
       "[1] 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "11"
      ],
      "text/latex": [
       "11"
      ],
      "text/markdown": [
       "11"
      ],
      "text/plain": [
       "[1] 11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(dat_list$tp)\n",
    "min(dat_list$tp)\n",
    "max(dat_list$tp)\n",
    "mean(dat_list2$tp)\n",
    "min(dat_list2$tp)\n",
    "max(dat_list2$tp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M1:\n",
    "at first, I check the data that see that we can have negative and\n",
    "positive so at first, I put zero for normal model a and the same\n",
    "for bT and bC but for variance, I check some numbers to get the\n",
    "best result for the first I check 1 but I know that the mean so near\n",
    "to zero so this number should be near to zero but I just want to\n",
    "check and get experience and for both bT and bC I know that this\n",
    "is slope and C and T they can just take two number of 1,2 because\n",
    "of mean the bT and bC obviously that must be less than 1 then I\n",
    "create my model I check n_eff and Rhat, the Rhat shows 1 so I’m\n",
    "in a good way but But the situation of n_eff is not very good its\n",
    "less than the 1000 and so far to 2000 for 4 chains. I tried different\n",
    "numbers and finally, I got to this model (you can see my tries and\n",
    "precis of each number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAMPLING FOR MODEL 'f2bedb0a0b842f9bd3910a1e624c98a9' NOW (CHAIN 1).\n",
      "Chain 1: \n",
      "Chain 1: Gradient evaluation took 0 seconds\n",
      "Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 1: Adjust your expectations accordingly!\n",
      "Chain 1: \n",
      "Chain 1: \n",
      "Chain 1: Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Chain 1: Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Chain 1: Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Chain 1: Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Chain 1: Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Chain 1: Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Chain 1: Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Chain 1: Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Chain 1: Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Chain 1: Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Chain 1: Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Chain 1: Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "Chain 1: \n",
      "Chain 1:  Elapsed Time: 0.203 seconds (Warm-up)\n",
      "Chain 1:                0.123 seconds (Sampling)\n",
      "Chain 1:                0.326 seconds (Total)\n",
      "Chain 1: \n",
      "\n",
      "SAMPLING FOR MODEL 'f2bedb0a0b842f9bd3910a1e624c98a9' NOW (CHAIN 2).\n",
      "Chain 2: \n",
      "Chain 2: Gradient evaluation took 0 seconds\n",
      "Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 2: Adjust your expectations accordingly!\n",
      "Chain 2: \n",
      "Chain 2: \n",
      "Chain 2: Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Chain 2: Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Chain 2: Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Chain 2: Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Chain 2: Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Chain 2: Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Chain 2: Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Chain 2: Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Chain 2: Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Chain 2: Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Chain 2: Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Chain 2: Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "Chain 2: \n",
      "Chain 2:  Elapsed Time: 0.195 seconds (Warm-up)\n",
      "Chain 2:                0.157 seconds (Sampling)\n",
      "Chain 2:                0.352 seconds (Total)\n",
      "Chain 2: \n",
      "\n",
      "SAMPLING FOR MODEL 'f2bedb0a0b842f9bd3910a1e624c98a9' NOW (CHAIN 3).\n",
      "Chain 3: \n",
      "Chain 3: Gradient evaluation took 0.001 seconds\n",
      "Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 10 seconds.\n",
      "Chain 3: Adjust your expectations accordingly!\n",
      "Chain 3: \n",
      "Chain 3: \n",
      "Chain 3: Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Chain 3: Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Chain 3: Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Chain 3: Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Chain 3: Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Chain 3: Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Chain 3: Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Chain 3: Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Chain 3: Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Chain 3: Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Chain 3: Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Chain 3: Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "Chain 3: \n",
      "Chain 3:  Elapsed Time: 0.12 seconds (Warm-up)\n",
      "Chain 3:                0.181 seconds (Sampling)\n",
      "Chain 3:                0.301 seconds (Total)\n",
      "Chain 3: \n",
      "\n",
      "SAMPLING FOR MODEL 'f2bedb0a0b842f9bd3910a1e624c98a9' NOW (CHAIN 4).\n",
      "Chain 4: \n",
      "Chain 4: Gradient evaluation took 0 seconds\n",
      "Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 4: Adjust your expectations accordingly!\n",
      "Chain 4: \n",
      "Chain 4: \n",
      "Chain 4: Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Chain 4: Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Chain 4: Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Chain 4: Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Chain 4: Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Chain 4: Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Chain 4: Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Chain 4: Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Chain 4: Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Chain 4: Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Chain 4: Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Chain 4: Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "Chain 4: \n",
      "Chain 4:  Elapsed Time: 0.118 seconds (Warm-up)\n",
      "Chain 4:                0.168 seconds (Sampling)\n",
      "Chain 4:                0.286 seconds (Total)\n",
      "Chain 4: \n"
     ]
    }
   ],
   "source": [
    "m1 <- ulam(\n",
    "  alist(\n",
    "    tp ~ dnorm(mu, sigma),\n",
    "    mu <- a + bT * T + bC * C,\n",
    "    a ~ dnorm(0, 0.2),\n",
    "    c(bT, bC) ~ dnorm(0, 0.5),\n",
    "    sigma ~ dexp(1)\n",
    "  ), data = dat_list, chains = 4, cores = 1, log_lik = TRUE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M2:\n",
    "m2 is the same as m1 Being as the likelihood is the same but it is an iteration model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAMPLING FOR MODEL '5e0d2402cb8453f2def0cff7bb6c8ba2' NOW (CHAIN 1).\n",
      "Chain 1: \n",
      "Chain 1: Gradient evaluation took 0 seconds\n",
      "Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 1: Adjust your expectations accordingly!\n",
      "Chain 1: \n",
      "Chain 1: \n",
      "Chain 1: Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Chain 1: Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Chain 1: Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Chain 1: Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Chain 1: Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Chain 1: Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Chain 1: Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Chain 1: Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Chain 1: Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Chain 1: Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Chain 1: Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Chain 1: Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "Chain 1: \n",
      "Chain 1:  Elapsed Time: 0.067 seconds (Warm-up)\n",
      "Chain 1:                0.059 seconds (Sampling)\n",
      "Chain 1:                0.126 seconds (Total)\n",
      "Chain 1: \n",
      "\n",
      "SAMPLING FOR MODEL '5e0d2402cb8453f2def0cff7bb6c8ba2' NOW (CHAIN 2).\n",
      "Chain 2: \n",
      "Chain 2: Gradient evaluation took 0 seconds\n",
      "Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 2: Adjust your expectations accordingly!\n",
      "Chain 2: \n",
      "Chain 2: \n",
      "Chain 2: Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Chain 2: Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Chain 2: Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Chain 2: Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Chain 2: Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Chain 2: Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Chain 2: Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Chain 2: Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Chain 2: Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Chain 2: Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Chain 2: Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Chain 2: Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "Chain 2: \n",
      "Chain 2:  Elapsed Time: 0.063 seconds (Warm-up)\n",
      "Chain 2:                0.05 seconds (Sampling)\n",
      "Chain 2:                0.113 seconds (Total)\n",
      "Chain 2: \n",
      "\n",
      "SAMPLING FOR MODEL '5e0d2402cb8453f2def0cff7bb6c8ba2' NOW (CHAIN 3).\n",
      "Chain 3: \n",
      "Chain 3: Gradient evaluation took 0 seconds\n",
      "Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 3: Adjust your expectations accordingly!\n",
      "Chain 3: \n",
      "Chain 3: \n",
      "Chain 3: Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Chain 3: Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Chain 3: Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Chain 3: Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Chain 3: Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Chain 3: Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Chain 3: Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Chain 3: Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Chain 3: Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Chain 3: Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Chain 3: Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Chain 3: Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "Chain 3: \n",
      "Chain 3:  Elapsed Time: 0.069 seconds (Warm-up)\n",
      "Chain 3:                0.054 seconds (Sampling)\n",
      "Chain 3:                0.123 seconds (Total)\n",
      "Chain 3: \n",
      "\n",
      "SAMPLING FOR MODEL '5e0d2402cb8453f2def0cff7bb6c8ba2' NOW (CHAIN 4).\n",
      "Chain 4: \n",
      "Chain 4: Gradient evaluation took 0 seconds\n",
      "Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 4: Adjust your expectations accordingly!\n",
      "Chain 4: \n",
      "Chain 4: \n",
      "Chain 4: Iteration:   1 / 1000 [  0%]  (Warmup)\n",
      "Chain 4: Iteration: 100 / 1000 [ 10%]  (Warmup)\n",
      "Chain 4: Iteration: 200 / 1000 [ 20%]  (Warmup)\n",
      "Chain 4: Iteration: 300 / 1000 [ 30%]  (Warmup)\n",
      "Chain 4: Iteration: 400 / 1000 [ 40%]  (Warmup)\n",
      "Chain 4: Iteration: 500 / 1000 [ 50%]  (Warmup)\n",
      "Chain 4: Iteration: 501 / 1000 [ 50%]  (Sampling)\n",
      "Chain 4: Iteration: 600 / 1000 [ 60%]  (Sampling)\n",
      "Chain 4: Iteration: 700 / 1000 [ 70%]  (Sampling)\n",
      "Chain 4: Iteration: 800 / 1000 [ 80%]  (Sampling)\n",
      "Chain 4: Iteration: 900 / 1000 [ 90%]  (Sampling)\n",
      "Chain 4: Iteration: 1000 / 1000 [100%]  (Sampling)\n",
      "Chain 4: \n",
      "Chain 4:  Elapsed Time: 0.064 seconds (Warm-up)\n",
      "Chain 4:                0.05 seconds (Sampling)\n",
      "Chain 4:                0.114 seconds (Total)\n",
      "Chain 4: \n"
     ]
    }
   ],
   "source": [
    "m2 <- ulam(\n",
    "  alist(\n",
    "    tp ~ dnorm(mu, sigma),\n",
    "    mu <- bt[T] + bc[C],\n",
    "    bt[T] ~ dnorm(0, 0.05),\n",
    "    bc[C] ~ dnorm(0, 0.05),\n",
    "    sigma ~ dexp(1)\n",
    "  ), data = dat_list, chains = 4, cores = 1, log_lik = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M3:\n",
    "I use Poisson so first I check to mean, min, max and then calculate the log of them and because of Poisson use discrete outcome so I use dat_list$tp so the result is 1.5 as mean, 0 as min and 2.4 as max so for log(lambda) I set 1.5 as a centre and 1.5 as variance too so now it is cover all number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAMPLING FOR MODEL '05a05b014e110ed6b2f4d44e2f7c12a5' NOW (CHAIN 1).\n",
      "Chain 1: \n",
      "Chain 1: Gradient evaluation took 0 seconds\n",
      "Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 1: Adjust your expectations accordingly!\n",
      "Chain 1: \n",
      "Chain 1: \n",
      "Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "Chain 1: \n",
      "Chain 1:  Elapsed Time: 0.086 seconds (Warm-up)\n",
      "Chain 1:                0.152 seconds (Sampling)\n",
      "Chain 1:                0.238 seconds (Total)\n",
      "Chain 1: \n",
      "\n",
      "SAMPLING FOR MODEL '05a05b014e110ed6b2f4d44e2f7c12a5' NOW (CHAIN 2).\n",
      "Chain 2: \n",
      "Chain 2: Gradient evaluation took 0 seconds\n",
      "Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 2: Adjust your expectations accordingly!\n",
      "Chain 2: \n",
      "Chain 2: \n",
      "Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "Chain 2: \n",
      "Chain 2:  Elapsed Time: 0.125 seconds (Warm-up)\n",
      "Chain 2:                0.09 seconds (Sampling)\n",
      "Chain 2:                0.215 seconds (Total)\n",
      "Chain 2: \n",
      "\n",
      "SAMPLING FOR MODEL '05a05b014e110ed6b2f4d44e2f7c12a5' NOW (CHAIN 3).\n",
      "Chain 3: \n",
      "Chain 3: Gradient evaluation took 0 seconds\n",
      "Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 3: Adjust your expectations accordingly!\n",
      "Chain 3: \n",
      "Chain 3: \n",
      "Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "Chain 3: \n",
      "Chain 3:  Elapsed Time: 0.095 seconds (Warm-up)\n",
      "Chain 3:                0.131 seconds (Sampling)\n",
      "Chain 3:                0.226 seconds (Total)\n",
      "Chain 3: \n",
      "\n",
      "SAMPLING FOR MODEL '05a05b014e110ed6b2f4d44e2f7c12a5' NOW (CHAIN 4).\n",
      "Chain 4: \n",
      "Chain 4: Gradient evaluation took 0 seconds\n",
      "Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 4: Adjust your expectations accordingly!\n",
      "Chain 4: \n",
      "Chain 4: \n",
      "Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "Chain 4: \n",
      "Chain 4:  Elapsed Time: 0.109 seconds (Warm-up)\n",
      "Chain 4:                0.088 seconds (Sampling)\n",
      "Chain 4:                0.197 seconds (Total)\n",
      "Chain 4: \n"
     ]
    }
   ],
   "source": [
    "m3 <- ulam(\n",
    "  alist(\n",
    "    tp ~ dpois(lambda),\n",
    "    log(lambda) <- a,\n",
    "    a ~ dnorm(1.5, 1.5)\n",
    "  ), data = dat_list2, chains = 4,  cores = 1, iter = 2000, log_lik = TRUE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M4:\n",
    "I just add more parameters and the prior for alpha is the same and for bt and bc, I know that T and C can get 1 and 2 and we need to negative them Considering that sometimes alpha maybe more and we need to Decrease it so I centre it with 0 but it should be less than 1 so we need a number less than .5 (because of 2) so I put 0.2(actually I test .5 and .4) but I get better result of 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAMPLING FOR MODEL '4c13148f85a054f5ee441b6d59453c7f' NOW (CHAIN 1).\n",
      "Chain 1: \n",
      "Chain 1: Gradient evaluation took 0 seconds\n",
      "Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 1: Adjust your expectations accordingly!\n",
      "Chain 1: \n",
      "Chain 1: \n",
      "Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "Chain 1: \n",
      "Chain 1:  Elapsed Time: 1.04 seconds (Warm-up)\n",
      "Chain 1:                0.964 seconds (Sampling)\n",
      "Chain 1:                2.004 seconds (Total)\n",
      "Chain 1: \n",
      "\n",
      "SAMPLING FOR MODEL '4c13148f85a054f5ee441b6d59453c7f' NOW (CHAIN 2).\n",
      "Chain 2: \n",
      "Chain 2: Gradient evaluation took 0 seconds\n",
      "Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 2: Adjust your expectations accordingly!\n",
      "Chain 2: \n",
      "Chain 2: \n",
      "Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "Chain 2: \n",
      "Chain 2:  Elapsed Time: 0.945 seconds (Warm-up)\n",
      "Chain 2:                0.966 seconds (Sampling)\n",
      "Chain 2:                1.911 seconds (Total)\n",
      "Chain 2: \n",
      "\n",
      "SAMPLING FOR MODEL '4c13148f85a054f5ee441b6d59453c7f' NOW (CHAIN 3).\n",
      "Chain 3: \n",
      "Chain 3: Gradient evaluation took 0 seconds\n",
      "Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 3: Adjust your expectations accordingly!\n",
      "Chain 3: \n",
      "Chain 3: \n",
      "Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "Chain 3: \n",
      "Chain 3:  Elapsed Time: 0.868 seconds (Warm-up)\n",
      "Chain 3:                0.808 seconds (Sampling)\n",
      "Chain 3:                1.676 seconds (Total)\n",
      "Chain 3: \n",
      "\n",
      "SAMPLING FOR MODEL '4c13148f85a054f5ee441b6d59453c7f' NOW (CHAIN 4).\n",
      "Chain 4: \n",
      "Chain 4: Gradient evaluation took 0 seconds\n",
      "Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 4: Adjust your expectations accordingly!\n",
      "Chain 4: \n",
      "Chain 4: \n",
      "Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "Chain 4: \n",
      "Chain 4:  Elapsed Time: 0.885 seconds (Warm-up)\n",
      "Chain 4:                1.012 seconds (Sampling)\n",
      "Chain 4:                1.897 seconds (Total)\n",
      "Chain 4: \n"
     ]
    }
   ],
   "source": [
    "m4 <- ulam(\n",
    "  alist(\n",
    "    tp ~ dpois(lambda),\n",
    "    log(lambda) <- a + bt[T]+bc[C],\n",
    "    a ~ dnorm(1.5, 1.5),\n",
    "    bt[T] ~ dnorm( 0, 0.2 ),\n",
    "    bc[C] ~ dnorm( 0, 0.2 )\n",
    "  ), data = dat_list2, chains = 4, cores=1 ,iter = 2000, log_lik = TRUE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M6:\n",
    "I use Gama-Poisson in this model, all priors are the same as Poisson(M3) Thanks to the link function is the same and I use the same parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m6 <- ulam(\n",
    "  alist(\n",
    "    tp ~ dgampois( lambda , phi ),\n",
    "    log(lambda) <- a + bt[T]+bc[C],\n",
    "    a ~ dnorm(1.5,.5),\n",
    "    bt[T] ~ dnorm( 0 , 0.2 ),\n",
    "    bc[C] ~ dnorm( 0 , 0.2 ),\n",
    "    phi ~ dexp(1)\n",
    "  ), data=dat_list2 ,cores=4, chains=4,cmdstan = TRUE ,iter = 2000 , log_lik=TRUE )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M5,M7,M8:\n",
    "these models created by just experience or technique to see that how much these variables effect, I explain that in further\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for all models i check prior and posterior predictive check and check\n",
    "Max and min values(plot is located at prior predictive check)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m5 <- ulam(\n",
    "  alist(\n",
    "    tp ~ dnorm(mu, sigma),\n",
    "    mu <- bt[T]  ,\n",
    "    bt[T] ~ dnorm(0, 0.05),\n",
    "    sigma ~ dexp(1)\n",
    "  ), data = dat_list, chains = 4, cores = 4, log_lik = TRUE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m7 <- ulam(\n",
    "  alist(\n",
    "    T ~ dgampois( lambda , phi ),\n",
    "    log(lambda) <- a + bt[T],\n",
    "    a ~ dnorm(1.5, .5),\n",
    "    bt[T] ~ dnorm( 0 , 0.2 ),\n",
    "    phi ~ dexp(1)\n",
    "  ), data=dat_list2 ,cores=4, chains=4,iter = 2000,\n",
    "  cmdstan = TRUE , log_lik=TRUE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m8 <- ulam(\n",
    "  alist(\n",
    "    T ~ dgampois( lambda , phi ),\n",
    "    log(lambda) <- a + bc[C],\n",
    "    a ~ dnorm(1.5, .5),\n",
    "    bc[C] ~ dnorm( 0 , 0.2 ),\n",
    "    phi ~ dexp(1)\n",
    "  ), data=dat_list2 ,cores=4, chains=4,iter = 2000,\n",
    "  cmdstan = TRUE , log_lik=TRUE )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare\n",
    "I write the compare code with 4models and the result shows that\n",
    "the m2(interaction Normal model) is better than m1(Normal model)\n",
    "and m1 is better than m4(interaction Poisson model) and m4 is better than m3(Standard Poisson model) (because in WAIC The lower\n",
    "WAIC is the better Model ) I checked to compare with the LOO\n",
    "function but I didn’t see anything change and everything is the\n",
    "same approximately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A compareIC: 4 × 6</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>WAIC</th><th scope=col>SE</th><th scope=col>dWAIC</th><th scope=col>dSE</th><th scope=col>pWAIC</th><th scope=col>weight</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>m2</th><td>398.1939</td><td>16.85586</td><td>  0.000000</td><td>       NA</td><td>1.5770888</td><td>7.442807e-01</td></tr>\n",
       "\t<tr><th scope=row>m1</th><td>400.3306</td><td>16.81607</td><td>  2.136676</td><td>0.9534032</td><td>2.9066005</td><td>2.557193e-01</td></tr>\n",
       "\t<tr><th scope=row>m4</th><td>590.7689</td><td>12.43417</td><td>192.574933</td><td>6.6838993</td><td>2.2878677</td><td>1.134022e-42</td></tr>\n",
       "\t<tr><th scope=row>m3</th><td>591.5131</td><td>13.36030</td><td>193.319135</td><td>4.7229913</td><td>0.8399014</td><td>7.816639e-43</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A compareIC: 4 × 6\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & WAIC & SE & dWAIC & dSE & pWAIC & weight\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\tm2 & 398.1939 & 16.85586 &   0.000000 &        NA & 1.5770888 & 7.442807e-01\\\\\n",
       "\tm1 & 400.3306 & 16.81607 &   2.136676 & 0.9534032 & 2.9066005 & 2.557193e-01\\\\\n",
       "\tm4 & 590.7689 & 12.43417 & 192.574933 & 6.6838993 & 2.2878677 & 1.134022e-42\\\\\n",
       "\tm3 & 591.5131 & 13.36030 & 193.319135 & 4.7229913 & 0.8399014 & 7.816639e-43\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A compareIC: 4 × 6\n",
       "\n",
       "| <!--/--> | WAIC &lt;dbl&gt; | SE &lt;dbl&gt; | dWAIC &lt;dbl&gt; | dSE &lt;dbl&gt; | pWAIC &lt;dbl&gt; | weight &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "| m2 | 398.1939 | 16.85586 |   0.000000 |        NA | 1.5770888 | 7.442807e-01 |\n",
       "| m1 | 400.3306 | 16.81607 |   2.136676 | 0.9534032 | 2.9066005 | 2.557193e-01 |\n",
       "| m4 | 590.7689 | 12.43417 | 192.574933 | 6.6838993 | 2.2878677 | 1.134022e-42 |\n",
       "| m3 | 591.5131 | 13.36030 | 193.319135 | 4.7229913 | 0.8399014 | 7.816639e-43 |\n",
       "\n"
      ],
      "text/plain": [
       "   WAIC     SE       dWAIC      dSE       pWAIC     weight      \n",
       "m2 398.1939 16.85586   0.000000        NA 1.5770888 7.442807e-01\n",
       "m1 400.3306 16.81607   2.136676 0.9534032 2.9066005 2.557193e-01\n",
       "m4 590.7689 12.43417 192.574933 6.6838993 2.2878677 1.134022e-42\n",
       "m3 591.5131 13.36030 193.319135 4.7229913 0.8399014 7.816639e-43"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare(m1, m2,m3,m4, func = WAIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A compareIC: 4 × 6</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>PSIS</th><th scope=col>SE</th><th scope=col>dPSIS</th><th scope=col>dSE</th><th scope=col>pPSIS</th><th scope=col>weight</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>m2</th><td>398.2014</td><td>16.91787</td><td>  0.000000</td><td>       NA</td><td>1.5808305</td><td>7.455901e-01</td></tr>\n",
       "\t<tr><th scope=row>m1</th><td>400.3519</td><td>16.87908</td><td>  2.150458</td><td>0.9539637</td><td>2.9172333</td><td>2.544099e-01</td></tr>\n",
       "\t<tr><th scope=row>m4</th><td>590.7783</td><td>12.47992</td><td>192.576915</td><td>6.6843565</td><td>2.2926006</td><td>1.134892e-42</td></tr>\n",
       "\t<tr><th scope=row>m3</th><td>591.5149</td><td>13.40844</td><td>193.313468</td><td>4.7242576</td><td>0.8408096</td><td>7.852610e-43</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A compareIC: 4 × 6\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & PSIS & SE & dPSIS & dSE & pPSIS & weight\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\tm2 & 398.2014 & 16.91787 &   0.000000 &        NA & 1.5808305 & 7.455901e-01\\\\\n",
       "\tm1 & 400.3519 & 16.87908 &   2.150458 & 0.9539637 & 2.9172333 & 2.544099e-01\\\\\n",
       "\tm4 & 590.7783 & 12.47992 & 192.576915 & 6.6843565 & 2.2926006 & 1.134892e-42\\\\\n",
       "\tm3 & 591.5149 & 13.40844 & 193.313468 & 4.7242576 & 0.8408096 & 7.852610e-43\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A compareIC: 4 × 6\n",
       "\n",
       "| <!--/--> | PSIS &lt;dbl&gt; | SE &lt;dbl&gt; | dPSIS &lt;dbl&gt; | dSE &lt;dbl&gt; | pPSIS &lt;dbl&gt; | weight &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "| m2 | 398.2014 | 16.91787 |   0.000000 |        NA | 1.5808305 | 7.455901e-01 |\n",
       "| m1 | 400.3519 | 16.87908 |   2.150458 | 0.9539637 | 2.9172333 | 2.544099e-01 |\n",
       "| m4 | 590.7783 | 12.47992 | 192.576915 | 6.6843565 | 2.2926006 | 1.134892e-42 |\n",
       "| m3 | 591.5149 | 13.40844 | 193.313468 | 4.7242576 | 0.8408096 | 7.852610e-43 |\n",
       "\n"
      ],
      "text/plain": [
       "   PSIS     SE       dPSIS      dSE       pPSIS     weight      \n",
       "m2 398.2014 16.91787   0.000000        NA 1.5808305 7.455901e-01\n",
       "m1 400.3519 16.87908   2.150458 0.9539637 2.9172333 2.544099e-01\n",
       "m4 590.7783 12.47992 192.576915 6.6843565 2.2926006 1.134892e-42\n",
       "m3 591.5149 13.40844 193.313468 4.7242576 0.8408096 7.852610e-43"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare(m1, m2,m3,m4, func = LOO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dags\n",
    "for dags first, I use daggity site and design my path 13 then I use both libraries (\"dagitty\", \"ggdag\") and write code to display dags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: 'ggdag'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:stats':\n",
      "\n",
      "    filter\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[90m# A DAG with 3 nodes and 2 edges\n",
       "\u001b[39m\u001b[90m#\n",
       "\u001b[39m\u001b[90m# Exposure: C, T\n",
       "\u001b[39m\u001b[90m# Outcome: TP\n",
       "\u001b[39m\u001b[90m#\n",
       "\u001b[39m\u001b[90m# A tibble: 3 x 8\u001b[39m\n",
       "  name      x     y direction to     xend  yend circular\n",
       "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<fct>\u001b[39m\u001b[23m     \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<lgl>\u001b[39m\u001b[23m   \n",
       "\u001b[90m1\u001b[39m C      29.0  24.9 ->        TP     27.8  24.9 FALSE   \n",
       "\u001b[90m2\u001b[39m T      26.7  24.9 ->        TP     27.8  24.9 FALSE   \n",
       "\u001b[90m3\u001b[39m TP     27.8  24.9 \u001b[31mNA\u001b[39m        \u001b[31mNA\u001b[39m     \u001b[31mNA\u001b[39m    \u001b[31mNA\u001b[39m   FALSE   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(dagitty)\n",
    "dag <- dagitty(\"dag{ T -> TP; C -> TP; }\")\n",
    "coordinates(dag) <- list(x = c(T = 0, TP = 1, C = 2), y = c(T = 0, TP = 0, C = 0)) # nolint\n",
    "drawdag(dag)\n",
    "\n",
    "\n",
    "library(ggdag)\n",
    "dag <- dagitty::dagitty(\"dag {\n",
    "    T -> TP <- C\n",
    "    C [exposure]\n",
    "    T [exposure]\n",
    "    TP [outcome]\n",
    "  }\")\n",
    "\n",
    "tidy_dag <- tidy_dagitty(dag)\n",
    "\n",
    "tidy_dag\n",
    "\n",
    "ggdag(tidy_dag) +\n",
    "    theme_dag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post <- extract.samples(m6)\n",
    "diff_T <- post$bt[,2] - post$bt[,1]\n",
    "precis(diff_T,depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post <- extract.samples(m7)\n",
    "post$diff_T <- post$bt[,2] - post$bt[,1]\n",
    "precis(post,depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post <- extract.samples(m8)\n",
    "diff_C <- post$bc[,2] - post$bc[,1]\n",
    "precis(diff_C,depth = 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
